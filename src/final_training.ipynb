{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d59ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def process_absa_dataset(input_path: str, output_path: str):\n",
    "    \"\"\"\n",
    "    Converts an ABSA dataset from raw JSONL format to a flat format with text, aspect, and sentiment columns.\n",
    "\n",
    "    Args:\n",
    "        input_path (str): Path to the input .jsonl file\n",
    "        output_path (str): Path to the output .csv file\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            entry = json.loads(line.strip())\n",
    "            text = entry.get(\"text\", \"\")\n",
    "            labels = entry.get(\"labels\", [])\n",
    "\n",
    "            for label in labels:\n",
    "                start, end, aspect_sentiment = label\n",
    "                if \"_\" in aspect_sentiment:\n",
    "                    *aspect_parts, sentiment = aspect_sentiment.split(\"_\")\n",
    "                    aspect = \"_\".join(aspect_parts)\n",
    "                else:\n",
    "                    aspect, sentiment = aspect_sentiment, \"neutral\"\n",
    "\n",
    "\n",
    "                processed_data.append({\n",
    "                    \"text\": text,\n",
    "                    \"aspect\": aspect,\n",
    "                    \"sentiment\": sentiment\n",
    "                })\n",
    "\n",
    "    # Save to CSV\n",
    "    df = pd.DataFrame(processed_data)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Processed dataset saved to: {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b23d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_file = \"review_with_aspect.jsonl\"\n",
    "output_file = \"aspect_based_sentiment.csv\"\n",
    "process_absa_dataset(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ee4de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = \"answerdotai/ModernBERT-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b927a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your preprocessed dataset\n",
    "df = pd.read_csv(\"aspect_based_sentiment.csv\")\n",
    "\n",
    "# Optional: label encoding\n",
    "label_map = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "df[\"label\"] = df[\"sentiment\"].map(label_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8c9efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "# Encode text + aspect as sentence pairs\n",
    "def encode_pair(row):\n",
    "    return tokenizer(\n",
    "        row[\"text\"],\n",
    "        row[\"aspect\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "# Example encoding (batching will come later)\n",
    "sample = df.iloc[0]\n",
    "encoded = encode_pair(sample)\n",
    "\n",
    "print(encoded.keys())  # Shows input_ids, attention_mask, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1040eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "class ABSADataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=128):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        inputs = self.tokenizer(\n",
    "            row[\"text\"],\n",
    "            row[\"aspect\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(row[\"label\"])\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a87fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Model\n",
    "class ModernBertClassifier(nn.Module):\n",
    "    def __init__(self, model_name, num_labels=3, dropout=0.3, classifier_layers=1, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        in_features = self.bert.config.hidden_size\n",
    "\n",
    "        if(classifier_layers == 1):\n",
    "            self.classifier = nn.Linear(in_features, num_labels)\n",
    "        elif classifier_layers == 2:\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Linear(in_features, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(hidden_dim, num_labels)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"classifier_layers must be 1 or 2\")\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = output.last_hidden_state[:, 0, :]\n",
    "        return self.classifier(self.dropout(cls_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f762629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['label'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n",
    "\n",
    "train_dataset = ABSADataset(train_df, tokenizer)\n",
    "val_dataset = ABSADataset(val_df, tokenizer)\n",
    "test_dataset = ABSADataset(test_df, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, num_workers=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, num_workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632d5d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train size: {len(train_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5f2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate(model, dataloader, compute_loss=False):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "            if compute_loss:\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "    avg_loss = total_loss / len(dataloader) if compute_loss else None\n",
    "    return acc, f1, avg_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a083b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline 1 - Majority class\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Prepare labels\n",
    "y_train = train_df[\"label\"]\n",
    "y_test = test_df[\"label\"]\n",
    "\n",
    "# Create and train dummy classifier\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit([[0]] * len(y_train), y_train)  # Fake features, labels only matter\n",
    "\n",
    "# Predict and evaluate\n",
    "dummy_preds = dummy.predict([[0]] * len(y_test))\n",
    "acc_dummy = accuracy_score(y_test, dummy_preds)\n",
    "f1_dummy = f1_score(y_test, dummy_preds, average=\"macro\")\n",
    "\n",
    "print(f\"Majority Class Baseline - Accuracy: {acc_dummy:.4f} | F1 Score: {f1_dummy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1ffeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline 2 - Logictic regression with TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Combine text + aspect for TF-IDF baseline (mimicking ABSA input)\n",
    "train_texts = (train_df[\"text\"] + \" [ASPECT] \" + train_df[\"aspect\"]).tolist()\n",
    "test_texts = (test_df[\"text\"] + \" [ASPECT] \" + test_df[\"aspect\"]).tolist()\n",
    "\n",
    "# Vectorize\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_test = vectorizer.transform(test_texts)\n",
    "\n",
    "y_train = train_df[\"label\"]\n",
    "y_test = test_df[\"label\"]\n",
    "\n",
    "# Train logistic regression\n",
    "clf = LogisticRegression(max_iter=200)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "baseline_preds = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, baseline_preds)\n",
    "f1 = f1_score(y_test, baseline_preds, average=\"macro\")\n",
    "\n",
    "print(f\"Logistic Regression Baseline - Accuracy: {acc:.4f} | F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a9b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "#Login wandb\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc2bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sweep config: Random search for LR, Dropout, and Architecture\n",
    "sweep_config = {\n",
    "    'method': 'random',  # grid search is tooo expensive.\n",
    "    'metric': {\n",
    "      'name': 'val_macro_f1',\n",
    "      'goal': 'maximize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "            'values': [1e-5, 2e-5, 3e-5]\n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0.1, 0.3, 0.5]\n",
    "        },\n",
    "        'classifier_layers': {\n",
    "            'values': [1, 2]   # 1 for single linear, 2 for hidden+output\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [32, 64, 128, 256]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370ef221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tqdm import tqdm  # <--- import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_sweep(config=None):\n",
    "    with wandb.init(config=config, name=\"test-run-with-1-epoch\"):\n",
    "        config = wandb.config\n",
    "\n",
    "        # ----- Model -----\n",
    "        model = ModernBertClassifier(\n",
    "            model_name=\"answerdotai/ModernBERT-base\",\n",
    "            num_labels=3,\n",
    "            dropout=config.dropout,\n",
    "            classifier_layers=config.classifier_layers\n",
    "        )\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "            model = torch.nn.DataParallel(model)\n",
    "        \n",
    "        model = model.to(device)\n",
    "\n",
    "        # ----- Data Loaders -----\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=8\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=8\n",
    "        )\n",
    "\n",
    "        # ----- Optimizer -----\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        num_epochs = 1  # Keep it short due to complexity.\n",
    "\n",
    "        best_macro_f1 = 0.0\n",
    "        for epoch in range(num_epochs):\n",
    "            # ----- TRAINING -----\n",
    "            model.train()\n",
    "            train_losses, train_labels, train_preds = [], [], []\n",
    "            train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", leave=False)\n",
    "            for batch in train_pbar:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_losses.append(loss.item())\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                train_labels.extend(labels.cpu().numpy())\n",
    "                train_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "            train_acc = accuracy_score(train_labels, train_preds)\n",
    "            train_f1 = f1_score(train_labels, train_preds, average='macro')\n",
    "\n",
    "            # ----- VALIDATION -----\n",
    "            model.eval()\n",
    "            val_losses, val_labels, val_preds = [], [], []\n",
    "            val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\", leave=False)\n",
    "            with torch.no_grad():\n",
    "                for batch in val_pbar:\n",
    "                    input_ids = batch['input_ids'].to(device)\n",
    "                    attention_mask = batch['attention_mask'].to(device)\n",
    "                    labels = batch['label'].to(device)\n",
    "\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    val_losses.append(loss.item())\n",
    "                    preds = torch.argmax(outputs, dim=1)\n",
    "                    val_labels.extend(labels.cpu().numpy())\n",
    "                    val_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "            val_acc = accuracy_score(val_labels, val_preds)\n",
    "            val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "            \n",
    "            # Print summary for your monitoring\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "                  f\"Train F1: {train_f1:.4f} | Val F1: {val_f1:.4f} | \"\n",
    "                  f\"Train Loss: {sum(train_losses)/len(train_losses):.4f} | \"\n",
    "                  f\"Val Loss: {sum(val_losses)/len(val_losses):.4f}\")\n",
    "\n",
    "            # Log to WANDB\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": sum(train_losses) / len(train_losses),\n",
    "                \"train_accuracy\": train_acc,\n",
    "                \"train_macro_f1\": train_f1,\n",
    "                \"val_loss\": sum(val_losses) / len(val_losses),\n",
    "                \"val_accuracy\": val_acc,\n",
    "                \"val_macro_f1\": val_f1\n",
    "            })\n",
    "\n",
    "            # Save best\n",
    "            if val_f1 > best_macro_f1:\n",
    "                best_macro_f1 = val_f1\n",
    "\n",
    "        # Log best macro-F1 at the end\n",
    "        wandb.log({\"best_val_macro_f1\": best_macro_f1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e40bfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"aspect-sentiment-modernbert\")\n",
    "print(f\"Sweep ID: {sweep_id}\")\n",
    "\n",
    "wandb.agent(sweep_id, function=train_sweep, count=3)  # Change count as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30831a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03ea127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
